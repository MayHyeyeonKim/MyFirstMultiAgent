import os
import warnings
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai_tools import ScrapeWebsiteTool
import tiktoken
from datetime import datetime
from IPython.display import Markdown  # Jupyterì—ì„œ ì“¸ ê²½ìš°ë§Œ ì‚¬ìš©ë¨

# ê²½ê³  ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
openai_api_key = os.getenv("OPENAI_API_KEY")
model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-3.5-turbo")

# í™˜ê²½ë³€ìˆ˜ ë“±ë¡
os.environ["OPENAI_API_KEY"] = openai_api_key
os.environ["OPENAI_MODEL_NAME"] = model_name


# Tool
class LimitedScrapeTool(ScrapeWebsiteTool):
    def _run(self, *args, **kwargs) -> str:
        url = kwargs.get("url", self.website_url)
        print(f"\nğŸŒ Scraping URL: {url}", flush=True)
        raw = super()._run(*args, **kwargs)
        print("ğŸ” Original length:", len(raw), flush=True)

        try:
            enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
        except Exception as e:
            print("ğŸš¨ Tokenizer loading failed:", e, flush=True)
            return raw[:1000]

        tokens = enc.encode(raw)
        print("ğŸ§® Original token count:", len(tokens), flush=True)

        max_token_limit = 1000
        shortened = enc.decode(tokens[:max_token_limit])
        print("âœ‚ï¸ Truncated to token count:", max_token_limit, flush=True)

        return shortened


# === Agents ì •ì˜ ===
planner = Agent(
    role="Content Planner",
    goal="Plan engaging and factually accurate content on {topic}",
    backstory=(
        "You're working on planning a blog article about the topic: {topic}. "
        "You collect information that helps the audience learn something "
        "and make informed decisions. Your work is the basis for the Content Writer to write an article."
    ),
    allow_delegation=False,  # Cooperation with other agents is not allowed
    verbose=True,
)

writer = Agent(
    role="Content Writer",
    goal="Write insightful and factually accurate opinion piece about the topic: {topic}",
    backstory=(
        "You're writing an opinion piece about the topic: {topic}. "
        "You base your writing on the Content Planner's work and provide objective and impartial insights."
        "Always support your edits with clear rationale. Do not guess or make assumptions without evidence."  # Gardrails
    ),
    allow_delegation=True,  # Cooperation with other agents is allowed, if Writer needs help, Writer can ask Planner or Editor for assistance
    verbose=True,
)

editor = Agent(
    role="Editor",
    goal="Edit a given blog post to align with the writing style of the organization.",
    backstory=(
        "You're an editor reviewing a blog post for clarity, tone, and journalistic best practices."
        "Avoid speculation. Only provide answers that are supported by facts or reliable sources."  # Gardrails
    ),
    allow_delegation=False,
    verbose=True,
)

# === Tasks ì •ì˜ ===

scrape_tool = LimitedScrapeTool(
    # website_url="https://en.wikipedia.org/wiki/Artificial_intelligence"
    website_url="https://www.ibm.com/topics/artificial-intelligence"
)  # CrewAI ë‚´ë¶€ì—ì„œëŠ” íˆ´ì„ ì‹¤í–‰í•  ë•Œ ì§ì ‘ LimitedScrapeTool._run() ì„ í˜¸ì¶œ

plan = Task(
    description=(
        "Before doing anything, print 'âœ… plan Task !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\n"
        "1. Prioritize the latest trends, key players, and noteworthy news on {topic}.\n"
        "2. Identify the target audience, considering their interests and pain points.\n"
        "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n"
        "4. Include SEO keywords and relevant data or sources."
    ),
    expected_output=(
        "A JSON object containing the following fields:\n"
        "- 'outline': list of blog sections with titles\n"
        "- 'audience': target demographics and pain points\n"
        "- 'keywords': list of suggested SEO keywords\n"
        "- 'sources': list of URLs or references used during research"
    ),
    tools=[
        scrape_tool
    ],  # Tool assigned at Task level (overrides Agent-level tools if both are set)
    agent=planner,
)

write = Task(
    description=(
        "Step 1 is done. Now proceed with Step 2.\n"
        "Use the selected blog title: {selected_title} as the main heading.\n"
        "Then write the blog post with the following structure:\n"
        "- Introduction (2â€“3 paragraphs)\n"
        "- Body (multiple well-structured sections)\n"
        "- Conclusion (summary + call to action)\n"
        "The blog must:\n"
        "- Incorporate SEO keywords naturally\n"
        "- Link to reliable sources when appropriate\n"
        "- Use markdown formatting with proper heading levels (###) and bullet points if helpful\n"
        "- Maintain a consistent and professional tone aligned with our brand"
    ),
    expected_output=(
        "A blog post in markdown format, including the following sections:\n"
        "- Introduction (2~3 paragraphs)\n"
        "- Body (well-structured, multiple sections)\n"
        "- Conclusion (summary + call to action)\n"
        "The post must:\n"
        "- Naturally include SEO keywords\n"
        "- Link to relevant sources where appropriate\n"
        "- Use heading levels (###) and bullet points if helpful"
    ),
    agent=writer,
)  # ë§Œì•½ ì—¬ëŸ¬ writerê°€ ë™ì‹œì— ë‹¤ë¥¸ ì„¹ì…˜ì„ ì“°ê²Œ í•œë‹¤ë©´? â†’ Taskë“¤ì„ Crew(parallel=True)ë¡œ ì„¤ì •. (í˜„ì¬ ì½”ë“œ êµ¬ì¡°ì—ì„  ë‹¨ì¼ íë¦„ì´ë¼ í•´ë‹¹ ì—†ìŒ. ë‹¤ì¤‘ ì½˜í…ì¸  ìƒì‚° ì‹œ ê³ ë ¤ ê°€ëŠ¥) <- ì´ê±´ êµ¬ì¡°ê°€ ë…ë¦½ì ì¼ ë•ŒëŠ” ë§ëŠ” ë§
# Crewì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ì—¬ëŸ¬ taskë¥¼ ë³‘ë ¬ë¡œ ë°°ì¹˜í•˜ëŠ” ê²½ìš° â†’ CrewAI êµ¬ì¡°ìƒ ë§ˆì§€ë§‰ taskë“¤ì€ ë³‘ë ¬ë¡œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ

edit = Task(
    description=("Proofread the blog post for grammatical errors and tone alignment."),
    expected_output=(
        "A final, professionally edited blog post in markdown format.\n"
        "The post should:\n"
        "- Be free of grammatical and spelling errors\n"
        "- Follow brand tone and journalistic style\n"
        "- Maintain the structure and intent of the original content\n"
        "- Be publication-ready"
    ),
    agent=editor,
)

# === Crew êµ¬ì„± ===
crew = Crew(
    agents=[planner, writer, editor],
    tasks=[plan, write, edit],
    verbose=False,
    memory=False,  # Enables short-term memory in CrewAI
    # long-term memory and entity memory are not currently supported in CrewAI
    # To persist knowledge across runs or track entities, manual implementation or integration with external memory backends (e.g., LangChain, ChromaDB) is required.
)

if __name__ == "__main__":
    topic = "Artificial Intelligence"

    # Step 1: ì œëª© 3ê°œë§Œ ë¨¼ì € ìƒì„± (writer agentë§Œ ì‚¬ìš©í•œ ë‹¨ë… taskë¡œ ì²˜ë¦¬)
    preview_write = Task(
        description=(
            "Generate 3 creative and engaging blog post title options related to the topic: {topic}.\n"
            "Format them as a numbered list like this:\n"
            "1. ...\n"
            "2. ...\n"
            "3. ...\n"
            "Pause and wait for the user to choose one."
        ),
        expected_output="Three numbered blog title options based on the topic.",
        agent=writer,
    )

    temp_crew = Crew(agents=[writer], tasks=[preview_write], verbose=True)
    result = temp_crew.kickoff(inputs={"topic": topic})
    print(result)

    # ì‚¬ìš©ì ì„ íƒ ë°›ê¸°
    print("\nğŸ‘€ Please choose one of the suggested titles (1, 2, or 3):")
    selected_title = input("ğŸ‘‰ Your selected blog title: ").strip()

    # ì„ íƒëœ ì œëª©ì„ ë³¸ë¬¸ ì‘ì„±ì— ë°˜ì˜í•˜ì—¬ main crew ì‹œì‘
    final_result = crew.kickoff(
        inputs={"topic": topic, "selected_title": selected_title}
    )
    text = str(final_result)

    print(final_result)

    # âœ… "###"ë¶€í„° ì‹œì‘í•˜ëŠ” ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì„œ ì €ì¥
    markdown_start_index = text.find("###")
    cleaned_text = text[markdown_start_index:] if markdown_start_index != -1 else text

    # ì €ì¥
    output_dir = "outputs"
    os.makedirs(output_dir, exist_ok=True)
    filename = f"blog_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    output_path = os.path.join(output_dir, filename)

    with open(output_path, "w") as f:
        f.write(cleaned_text)

# ì‹¤ì œ í˜¸ì¶œ íë¦„:
# crew.kickoff()
#   â””â”€> AgentExecutor sees â€œRead website contentâ€
#         â””â”€> scrape_tool.run(...)  # BaseTool.run
#               â””â”€> scrape_tool._run(...)  # override í•œ ê³³!
